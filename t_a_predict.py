# -*- coding: utf-8 -*-
"""T-A_predict.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1QfAqwhCey-bmWqF7H_7TChexpQ1cfs-C
"""

# Google Colabで必要なライブラリをインストール
!pip install torch torchvision pandas matplotlib scikit-learn

# 必要なライブラリをインポート
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, random_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix, classification_report
from IPython.display import clear_output

# データセットクラスを定義
class AnxietyDataset(Dataset):
    def __init__(self, data, column):
        self.data = data
        self.features = data[column].values
        self.targets = data['T-A'].values

    def __len__(self):
        return len(self.data)

    def __getitem__(self, index):
        x = self.features[index]
        y = self.targets[index]
        return torch.tensor(x, dtype=torch.float32), torch.tensor(y, dtype=torch.float32)

# ニューラルネットワークモデルを定義
class AnxietyPredictor(nn.Module):
    def __init__(self, input_dim):
        super(AnxietyPredictor, self).__init__()
        self.fc1 = nn.Linear(input_dim, 16)
        self.fc2 = nn.Linear(16, 8)
        self.fc3 = nn.Linear(8, 1)
        self.dropout1 = nn.Dropout(0.1)
        self.dropout2 = nn.Dropout(0.1)

    def forward(self, x):
        x = torch.relu(self.fc1(x))
        x = self.dropout1(x)
        x = torch.relu(self.fc2(x))
        x = self.dropout2(x)
        x = self.fc3(x)
        return x

# トレーニングループを定義
def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs):
    train_loss_values = []
    val_loss_values = []

    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        for inputs, targets in train_loader:
            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs.squeeze(), targets)
            loss.backward()
            optimizer.step()
            running_loss += loss.item() * inputs.size(0)

        epoch_loss = running_loss / len(train_loader.dataset)
        train_loss_values.append(epoch_loss)

        model.eval()
        val_running_loss = 0.0
        with torch.no_grad():
            for inputs, targets in val_loader:
                outputs = model(inputs)
                loss = criterion(outputs.squeeze(), targets)
                val_running_loss += loss.item() * inputs.size(0)

        val_epoch_loss = val_running_loss / len(val_loader.dataset)
        val_loss_values.append(val_epoch_loss)

        print(f'Epoch {epoch + 1}/{num_epochs}, Train Loss: {epoch_loss:.4f}, Val Loss: {val_epoch_loss:.4f}')

        # リアルタイムプロットの更新
        clear_output(wait=True)
        plt.figure(figsize=(10, 5))
        plt.plot(train_loss_values, label='Training Loss')
        plt.plot(val_loss_values, label='Validation Loss')
        plt.xlabel('Epoch')
        plt.ylabel('Loss')
        plt.ylim(0, 200)  # 損失が200以下の領域に限定
        plt.title('Training and Validation Loss Over Epochs')
        plt.legend()
        plt.show()

def evaluate_model(model, test_loader, threshold=5):
    model.eval()
    true_values = []
    predictions = []
    with torch.no_grad():
        for inputs, targets in test_loader:
            outputs = model(inputs)
            true_values.extend(targets.numpy())
            predictions.extend(outputs.numpy())

    # タスクの成功の定義を適用して二値分類を行う
    predicted_labels = [1 if abs(pred - true) <= threshold else 0 for pred, true in zip(predictions, true_values)]
    true_labels = [1] * len(true_values)  # 全てのtrue_valuesが閾値以内であれば正解とするため1とする

    # 混同行列と分類レポートの表示
    cm = confusion_matrix(true_labels, predicted_labels)
    cr = classification_report(true_labels, predicted_labels)

    print("Confusion Matrix:")
    print(cm)
    print("\nClassification Report:")
    print(cr)

import pandas as pd
from sklearn.model_selection import train_test_split
from torch.utils.data import DataLoader
import torch.nn as nn
import torch.optim as optim

# データの読み込み
train_path = '/content/train.csv'
test_path = '/content/test.csv'

train_data = pd.read_csv(train_path)
test_data = pd.read_csv(test_path)

# データをトレーニングと検証セットに分割
train_data, val_data = train_test_split(train_data, test_size=0.20, random_state=42)

use_column = ['heart', 'steps', 'drinking', '在宅の有無']
train_dataset = AnxietyDataset(train_data, use_column)
val_dataset = AnxietyDataset(val_data, use_column)
test_dataset = AnxietyDataset(test_data, use_column)

train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=16, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=16, shuffle=False)

# モデル、損失関数、オプティマイザーの定義
input_dim = len(use_column)  # 'heart', 'steps', 'drinking', 'caffeine', '在宅の有無', 'sleep'
model = AnxietyPredictor(input_dim)
criterion = nn.MSELoss()
learning_rate = 1e-3
optimizer = optim.Adam(model.parameters(), lr=learning_rate)

# モデルのトレーニング
num_epochs = 100
train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs)

# モデルの評価
evaluate_model(model, test_loader, threshold=5)